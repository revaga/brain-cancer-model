Epoch [1/2], Loss: 1.3929
Epoch [1/2], Loss: 5.7515
Epoch [1/2], Loss: 5.3822
Epoch [1/2], Loss: 2.8175
Epoch [1/2], Loss: 1.7632
Epoch [1/2], Loss: 1.6611
Epoch [1/2], Loss: 1.3872
Epoch [1/2], Loss: 1.3243
Epoch [1/2], Loss: 1.2803
Epoch [1/2], Loss: 1.1977
Epoch [1/2], Loss: 1.2493
Epoch [1/2], Loss: 1.2878
Epoch [1/2], Loss: 1.1333
Epoch [1/2], Loss: 1.2323
Epoch [1/2], Loss: 1.2678
Epoch [1/2], Loss: 1.1572
Epoch [1/2], Loss: 1.2994
Epoch [1/2], Loss: 1.2236
Epoch [1/2], Loss: 1.3304
Epoch [1/2], Loss: 1.2116
Epoch [1/2], Loss: 1.0945
Epoch [1/2], Loss: 1.2181
Epoch [1/2], Loss: 1.2552
Epoch [1/2], Loss: 1.2084
Epoch [1/2], Loss: 0.9873
Epoch [1/2], Loss: 1.1597
Epoch [1/2], Loss: 1.2065
Epoch [1/2], Loss: 1.1014
Epoch [1/2], Loss: 1.0229
Epoch [1/2], Loss: 0.8977
Epoch [1/2], Loss: 0.9261
Epoch [1/2], Loss: 0.8141
Epoch [1/2], Loss: 0.8959
Epoch [1/2], Loss: 0.7999
Epoch [1/2], Loss: 1.0390
Epoch [1/2], Loss: 0.8537
Epoch [1/2], Loss: 1.3156
Epoch [1/2], Loss: 0.8533
Epoch [1/2], Loss: 0.9202
Epoch [1/2], Loss: 1.1368
Epoch [1/2], Loss: 1.1464
Epoch [1/2], Loss: 0.9043
Epoch [1/2], Loss: 1.0052
Epoch [1/2], Loss: 0.9137
Epoch [1/2], Loss: 1.0677
Epoch [1/2], Loss: 0.8530
Epoch [1/2], Loss: 1.0370
Epoch [1/2], Loss: 0.5546
Epoch [1/2], Loss: 1.1632
Epoch [1/2], Loss: 0.7742
Epoch [1/2], Loss: 0.6852
Epoch [1/2], Loss: 0.8940
Epoch [1/2], Loss: 0.8621
Epoch [1/2], Loss: 0.9455
Epoch [1/2], Loss: 0.5878
Epoch [1/2], Loss: 0.8057
Epoch [1/2], Loss: 1.0525
Epoch [1/2], Loss: 0.8306
Epoch [1/2], Loss: 0.8465
Epoch [1/2], Loss: 0.8668
Epoch [1/2], Loss: 0.6669
Epoch [1/2], Loss: 0.7992
Epoch [1/2], Loss: 0.8910
Epoch [1/2], Loss: 0.9042
Epoch [1/2], Loss: 0.9697
Epoch [1/2], Loss: 0.9038
Epoch [1/2], Loss: 0.7381
Epoch [1/2], Loss: 0.6881
Epoch [1/2], Loss: 0.7924
Epoch [1/2], Loss: 0.9849
Epoch [1/2], Loss: 0.8557
Epoch [1/2], Loss: 0.5570
Epoch [1/2], Loss: 0.8070
Epoch [1/2], Loss: 0.9063
Epoch [1/2], Loss: 0.9023
Epoch [1/2], Loss: 0.7931
Epoch [1/2], Loss: 0.8385
Epoch [1/2], Loss: 0.8623
Epoch [1/2], Loss: 0.8945
Epoch [1/2], Loss: 0.7805
Epoch [1/2], Loss: 0.6223
Epoch [1/2], Loss: 0.7936
Epoch [1/2], Loss: 0.7903
Epoch [1/2], Loss: 0.6500
Epoch [1/2], Loss: 0.8815
Epoch [1/2], Loss: 0.9354
Epoch [1/2], Loss: 0.8134
Epoch [1/2], Loss: 0.5019
Epoch [1/2], Loss: 0.7359
Epoch [1/2], Loss: 0.5607
Epoch [1/2], Loss: 0.7427
Epoch [1/2], Loss: 0.7105
Epoch [1/2], Loss: 0.7038
Epoch [1/2], Loss: 0.6918
Epoch [1/2], Loss: 0.6081
Epoch [1/2], Loss: 0.6822
Epoch [1/2], Loss: 0.5746
Epoch [1/2], Loss: 0.6583
Epoch [1/2], Loss: 0.6935
Epoch [1/2], Loss: 0.5391
Epoch [1/2], Loss: 0.9487
Epoch [1/2], Loss: 0.5423
Epoch [1/2], Loss: 0.4410
Epoch [1/2], Loss: 0.4930
Epoch [1/2], Loss: 1.2933
Epoch [1/2], Loss: 0.6027
Epoch [1/2], Loss: 0.5350
Epoch [1/2], Loss: 0.8192
Epoch [1/2], Loss: 0.7629
Epoch [1/2], Loss: 0.6626
Epoch [1/2], Loss: 0.6190
Epoch [1/2], Loss: 0.4980
Epoch [1/2], Loss: 0.6899
Epoch [1/2], Loss: 0.8339
Epoch [1/2], Loss: 0.6316
Epoch [1/2], Loss: 0.8863
Epoch [1/2], Loss: 1.0741
Epoch [1/2], Loss: 0.5367
Epoch [1/2], Loss: 1.0148
Epoch [1/2], Loss: 0.5513
Epoch [1/2], Loss: 0.8548
Epoch [1/2], Loss: 0.5014
Epoch [1/2], Loss: 0.5011
Epoch [1/2], Loss: 0.5920
Epoch [1/2], Loss: 0.7391
Epoch [1/2], Loss: 0.5080
Epoch [1/2], Loss: 1.0384
Epoch [1/2], Loss: 0.7883
Epoch [1/2], Loss: 0.6235
Epoch [1/2], Loss: 0.6492
Epoch [1/2], Loss: 1.1237
Epoch [1/2], Loss: 0.7573
Epoch [1/2], Loss: 0.8813
Epoch [1/2], Loss: 0.6743
Epoch [1/2], Loss: 0.8383
Epoch [1/2], Loss: 0.7996
Epoch [1/2], Loss: 0.5990
Epoch [1/2], Loss: 0.7607
Epoch [1/2], Loss: 0.6568
Epoch [1/2], Loss: 0.6890
Epoch [1/2], Loss: 0.6209
Epoch [1/2], Loss: 0.6003
Epoch [1/2], Loss: 0.4895
Epoch [1/2], Loss: 0.4866
Epoch [1/2], Loss: 0.6775
Epoch [1/2], Loss: 0.5255
Epoch [1/2], Loss: 1.0677
Epoch [1/2], Loss: 0.4834
Epoch [1/2], Loss: 0.3140
Epoch [1/2], Loss: 0.4141
Epoch [1/2], Loss: 0.6923
Epoch [1/2], Loss: 0.6816
Epoch [1/2], Loss: 0.7479
Epoch [1/2], Loss: 0.4951
Epoch [1/2], Loss: 0.5132
Epoch [1/2], Loss: 0.3754
Epoch [1/2], Loss: 0.4396
Epoch [1/2], Loss: 0.5138
Epoch [1/2], Loss: 0.4739
Epoch [1/2], Loss: 1.1232
Epoch [1/2], Loss: 0.6347
Epoch [1/2], Loss: 0.6708
Epoch [1/2], Loss: 0.4725
Epoch [1/2], Loss: 0.9483
Epoch [1/2], Loss: 0.7122
Epoch [1/2], Loss: 0.5561
Epoch [1/2], Loss: 0.4535
Epoch [1/2], Loss: 0.7811
Epoch [1/2], Loss: 0.5520
Epoch [1/2], Loss: 0.9242
Epoch [1/2], Loss: 0.7386
Epoch [1/2], Loss: 0.5352
Epoch [1/2], Loss: 0.5816
Epoch [1/2], Loss: 0.9231
Epoch [1/2], Loss: 0.7610
Epoch [1/2], Loss: 0.9267
Epoch [1/2], Loss: 0.4017
Epoch [1/2], Loss: 0.5593
Traceback (most recent call last):
  File "/home/reva/CMPM17-ML/brain-cancer-model/training_loop.py", line 304, in <module>
    for val_inputs, val_labels in val_loader:
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 764, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/reva/CMPM17-ML/brain-cancer-model/training_loop.py", line 144, in __getitem__
    label = self.labels[idx]
            ~~~~~~~~~~~^^^^^
IndexError: list index out of range
