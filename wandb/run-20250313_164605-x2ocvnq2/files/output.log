Epoch [1/10], Loss: 1.3834
Epoch [1/10], Loss: 11.0210
Epoch [1/10], Loss: 2.7029
Epoch [1/10], Loss: 2.3303
Epoch [1/10], Loss: 1.9365
Epoch [1/10], Loss: 1.3702
Epoch [1/10], Loss: 1.2854
Epoch [1/10], Loss: 1.2739
Epoch [1/10], Loss: 1.1550
Epoch [1/10], Loss: 1.4200
Epoch [1/10], Loss: 1.2547
Epoch [1/10], Loss: 1.2655
Epoch [1/10], Loss: 1.0948
Epoch [1/10], Loss: 1.2212
Epoch [1/10], Loss: 1.0697
Epoch [1/10], Loss: 1.1538
Epoch [1/10], Loss: 1.1173
Epoch [1/10], Loss: 1.2807
Epoch [1/10], Loss: 1.1286
Epoch [1/10], Loss: 1.0178
Epoch [1/10], Loss: 1.1060
Epoch [1/10], Loss: 1.0171
Epoch [1/10], Loss: 0.8648
Epoch [1/10], Loss: 1.0162
Epoch [1/10], Loss: 0.8024
Epoch [1/10], Loss: 0.9665
Epoch [1/10], Loss: 1.0010
Epoch [1/10], Loss: 0.8184
Epoch [1/10], Loss: 1.0717
Epoch [1/10], Loss: 0.7088
Epoch [1/10], Loss: 0.7473
Epoch [1/10], Loss: 0.8529
Epoch [1/10], Loss: 0.8038
Epoch [1/10], Loss: 0.7811
Epoch [1/10], Loss: 0.8085
Epoch [1/10], Loss: 0.4198
Epoch [1/10], Loss: 0.7650
Epoch [1/10], Loss: 0.7137
Epoch [1/10], Loss: 0.6166
Epoch [1/10], Loss: 0.8960
Epoch [1/10], Loss: 0.7945
Epoch [1/10], Loss: 1.1363
Epoch [1/10], Loss: 0.6305
Epoch [1/10], Loss: 0.6466
Epoch [1/10], Loss: 0.5785
Epoch [1/10], Loss: 0.7457
Epoch [1/10], Loss: 0.3835
Epoch [1/10], Loss: 0.5584
Epoch [1/10], Loss: 0.6568
Epoch [1/10], Loss: 0.7711
Epoch [1/10], Loss: 0.7814
Epoch [1/10], Loss: 0.7845
Epoch [1/10], Loss: 0.5789
Epoch [1/10], Loss: 0.5930
Epoch [1/10], Loss: 0.7712
Epoch [1/10], Loss: 0.8286
Epoch [1/10], Loss: 1.1211
Epoch [1/10], Loss: 1.0056
Epoch [1/10], Loss: 0.8365
Epoch [1/10], Loss: 0.7913
Epoch [1/10], Loss: 0.8172
Epoch [1/10], Loss: 0.8539
Epoch [1/10], Loss: 0.6212
Epoch [1/10], Loss: 0.8348
Epoch [1/10], Loss: 0.8288
Epoch [1/10], Loss: 0.8853
Epoch [1/10], Loss: 0.5966
Epoch [1/10], Loss: 1.0131
Epoch [1/10], Loss: 0.6504
Epoch [1/10], Loss: 0.8897
Epoch [1/10], Loss: 0.5903
Epoch [1/10], Loss: 0.9013
Epoch [1/10], Loss: 1.0205
Epoch [1/10], Loss: 0.7666
Epoch [1/10], Loss: 0.5631
Epoch [1/10], Loss: 0.6426
Epoch [1/10], Loss: 0.6480
Epoch [1/10], Loss: 0.7152
Epoch [1/10], Loss: 0.6955
Epoch [1/10], Loss: 0.7936
Epoch [1/10], Loss: 0.5227
Epoch [1/10], Loss: 0.8038
Epoch [1/10], Loss: 0.3941
Epoch [1/10], Loss: 0.6791
Epoch [1/10], Loss: 0.3957
Epoch [1/10], Loss: 0.7180
Epoch [1/10], Loss: 0.5179
Epoch [1/10], Loss: 0.7365
Epoch [1/10], Loss: 0.7339
Epoch [1/10], Loss: 1.0824
Epoch [1/10], Loss: 1.0973
Epoch [1/10], Loss: 0.4732
Epoch [1/10], Loss: 0.4518
Epoch [1/10], Loss: 0.9397
Epoch [1/10], Loss: 0.8393
Epoch [1/10], Loss: 0.9080
Epoch [1/10], Loss: 0.7718
Epoch [1/10], Loss: 0.7112
Epoch [1/10], Loss: 0.6593
Epoch [1/10], Loss: 0.9024
Epoch [1/10], Loss: 0.6575
Epoch [1/10], Loss: 0.7951
Epoch [1/10], Loss: 0.9773
Epoch [1/10], Loss: 0.7331
Epoch [1/10], Loss: 0.7109
Epoch [1/10], Loss: 0.6630
Epoch [1/10], Loss: 0.7483
Epoch [1/10], Loss: 0.6335
Epoch [1/10], Loss: 0.8635
Epoch [1/10], Loss: 0.5813
Epoch [1/10], Loss: 0.7027
Epoch [1/10], Loss: 0.7631
Epoch [1/10], Loss: 0.6509
Epoch [1/10], Loss: 0.5521
Epoch [1/10], Loss: 0.5897
Epoch [1/10], Loss: 0.7169
Epoch [1/10], Loss: 0.6168
Epoch [1/10], Loss: 0.4033
Epoch [1/10], Loss: 0.6717
Epoch [1/10], Loss: 0.6586
Epoch [1/10], Loss: 0.8473
Epoch [1/10], Loss: 0.7853
Epoch [1/10], Loss: 0.5734
Epoch [1/10], Loss: 0.7175
Epoch [1/10], Loss: 0.7565
Epoch [1/10], Loss: 0.7462
Epoch [1/10], Loss: 0.5560
Epoch [1/10], Loss: 0.6952
Epoch [1/10], Loss: 0.4748
Epoch [1/10], Loss: 0.5120
Epoch [1/10], Loss: 0.6772
Epoch [1/10], Loss: 0.5168
Epoch [1/10], Loss: 0.6735
Epoch [1/10], Loss: 0.4368
Epoch [1/10], Loss: 0.3941
Epoch [1/10], Loss: 0.5500
Epoch [1/10], Loss: 0.6995
Epoch [1/10], Loss: 0.4703
Epoch [1/10], Loss: 0.6563
Epoch [1/10], Loss: 0.5804
Epoch [1/10], Loss: 0.9042
Epoch [1/10], Loss: 0.6719
Epoch [1/10], Loss: 0.3677
Epoch [1/10], Loss: 0.6872
Epoch [1/10], Loss: 0.4666
Epoch [1/10], Loss: 0.7172
Epoch [1/10], Loss: 0.7708
Epoch [1/10], Loss: 0.3486
Epoch [1/10], Loss: 0.4664
Epoch [1/10], Loss: 0.5914
Epoch [1/10], Loss: 0.5335
Epoch [1/10], Loss: 0.3881
Epoch [1/10], Loss: 0.8910
Traceback (most recent call last):
  File "/home/reva/CMPM17-ML/brain-cancer-model/training_loop.py", line 256, in <module>
    for inputs, labels in train_loader:
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 764, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/reva/CMPM17-ML/brain-cancer-model/training_loop.py", line 137, in __getitem__
    image = self.transform(image)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py", line 51, in forward
    outputs = transform(*inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py", line 69, in forward
    self.transform(inpt, params) if needs_transform else inpt
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torchvision/transforms/v2/_geometry.py", line 627, in transform
    return self._call_kernel(
           ^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py", line 49, in _call_kernel
    return kernel(inpt, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py", line 1039, in rotate_image
    return _apply_grid_transform(image, grid, interpolation.value, fill=fill)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py", line 622, in _apply_grid_transform
    float_img = grid_sample(float_img, grid, mode=mode, padding_mode="zeros", align_corners=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/reva/VENV-NAME/lib/python3.12/site-packages/torch/nn/functional.py", line 5023, in grid_sample
    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
